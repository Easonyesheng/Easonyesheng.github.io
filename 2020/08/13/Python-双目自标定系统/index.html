

<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Python实现的双目相机自标定系统 - 指北集</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="google" content="notranslate" />

  
  
  <meta name="description" content="Python实现的双目相机自标定系统
Requirem..."> 
  
  <meta name="author" content="Eason Zhang"> 

  
    <link rel="icon" href="http://easonzhangyesheng.gitee.io/imgnorthpointer/icon.ico" type="image/png" sizes="16x16">
  
  
    <link rel="icon" href="http://easonzhangyesheng.gitee.io/imgnorthpointer/icon.ico" type="image/png" sizes="32x32">
  
  
    <link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png" sizes="180x180">
  
  
    <meta rel="mask-icon" href="/images/icons/stun-logo.svg" color="#333333">
  
  
    <meta rel="msapplication-TileImage" content="/images/icons/favicon-144x144.png">
    <meta rel="msapplication-TileColor" content="#000000">
  

  
<link rel="stylesheet" href="/css/style.css">


  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1445822_0sri83bhiv7.css">

  

  
  
  
<link rel="stylesheet" href="https://cdn.bootcss.com/fancybox/3.5.7/jquery.fancybox.min.css">

  

  
  
  
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/xcode.min.css">

  

  

  <script>
    var CONFIG = window.CONFIG || {};
    var ZHAOO = window.ZHAOO || {};
    CONFIG = {
      fancybox: true,
      pjax: false,
      lazyload: {
        enable: true,
        loadingImage: '/images/theme/loading.gif',
      },
      donate_alipay: '',
      donate_wechat: '',
      motto: {
        api: '',
        default: '21世纪漫游指北。'
      },
      galleries: {
        enable: 'false'
      },
      fab: {
        enable: 'true',
        alwaysShow: 'false'
      },
      carrier: {
        enable: 'true'
      },
      daovoice: {
        enable: 'true'
      }
    }
  </script>

  

  
<meta name="generator" content="Hexo 5.0.2"><link rel="alternate" href="/atom.xml" title="指北集" type="application/atom+xml">
</head>
<body class="lock-screen">
  <div class="loading"></div>
  <nav class="menu">
  <div class="menu-close">
    <i class="iconfont iconplus"></i>
  </div>
  <ul class="menu-content">
    
    
    
    
    <li class="menu-item"><a href="/ "> 首页</a></li>
    
    
    
    
    <li class="menu-item"><a href="/archives "> 归档</a></li>
    
    
    
    
    <li class="menu-item"><a href="/tags "> 标签</a></li>
    
    
    
    
    <li class="menu-item"><a href="/categories "> 分类</a></li>
    
    
    
    
    <li class="menu-item"><a href="/about "> 关于</a></li>
    
  </ul>
  <div class="menu-copyright"><p>Copyright© 2019-2020 | <a target="_blank" href="https://northpointer.xyz">zhaoo</a> .AllRightsReserved</p></div>
</nav>
  <main id="main">
  <div class="container" id="container">
    <article class="article">
  <section class="head">
  <img   class="lazyload" data-original="http://easonzhangyesheng.gitee.io/imgnorthpointer/bg1.jpeg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  draggable="false">
  <div class="head-mask">
    <h1 class="head-title">Python实现的双目相机自标定系统</h1>
    <div class="head-info">
      <span class="post-info-item"><i class="iconfont iconcalendar"></i>2020-08-13</span
        class="post-info-item">
      
      <span class="post-info-item"><i class="iconfont iconfont-size"></i>11148</span>
    </div>
  </div>
</section>
  <section class="main">
    <section class="content">
      <h1 id="Python实现的双目相机自标定系统"><a href="#Python实现的双目相机自标定系统" class="headerlink" title="Python实现的双目相机自标定系统"></a>Python实现的双目相机自标定系统</h1><hr>
<h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><p>python-opencv 3.14<br>numpy<br>os<br>sys  </p>
<hr>
<h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><div id="flowchart-0" class="flow-chart"></div>

<hr>
<h2 id="读入图片和参数"><a href="#读入图片和参数" class="headerlink" title="读入图片和参数"></a>读入图片和参数</h2><p>图片是使用常规的imread，重点是参数的读取。<br>这里选取的参数是kitti的标定文件，读取方式如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Paser</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Paser the calib_file </span></span><br><span class="line"><span class="string">    return a dictionary</span></span><br><span class="line"><span class="string">    use it as :</span></span><br><span class="line"><span class="string">        calib = self.Paser()</span></span><br><span class="line"><span class="string">        K1, K2 = self.calib[&#x27;K_0&#123;&#125;&#x27;.format(f_cam)], self.calib[&#x27;K_0&#123;&#125;&#x27;.format(t_cam)]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    d = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> open(self.calib_path) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> f:</span><br><span class="line">            <span class="keyword">if</span> l.startswith(<span class="string">&quot;calib_time&quot;</span>):</span><br><span class="line">                d[<span class="string">&quot;calib_time&quot;</span>] = l[l.index(<span class="string">&quot;calib_time&quot;</span>)+<span class="number">1</span>:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                [k,v] = l.split(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">                k,v = k.strip(), v.strip()</span><br><span class="line">                <span class="comment">#get the numbers out</span></span><br><span class="line">                v = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> v.strip().split(<span class="string">&quot; &quot;</span>)]</span><br><span class="line">                v = np.array(v)</span><br><span class="line">                <span class="keyword">if</span> len(v) == <span class="number">9</span>:</span><br><span class="line">                    v = v.reshape((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">                <span class="keyword">elif</span> len(v) == <span class="number">3</span>:</span><br><span class="line">                    v = v.reshape((<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">                <span class="keyword">elif</span> len(v) == <span class="number">5</span>:</span><br><span class="line">                    v = v.reshape((<span class="number">5</span>,<span class="number">1</span>))</span><br><span class="line">                d[k] = v</span><br><span class="line">    <span class="keyword">return</span> d</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="估计基础矩阵"><a href="#估计基础矩阵" class="headerlink" title="估计基础矩阵"></a>估计基础矩阵</h2><p>基础矩阵的估计采用的是传统的算法，可选的是<strong>SIFT+RANSAC</strong>和<strong>SIFT+LMedS</strong>。<br>关键代码如下：  </p>
<p>提取特征点算法SIFT:  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"></span><br><span class="line"><span class="comment"># find the keypoints and descriptors with SIFT</span></span><br><span class="line">kp1, des1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">kp2, des2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># FLANN parameters</span></span><br><span class="line">FLANN_INDEX_KDTREE = <span class="number">0</span></span><br><span class="line">index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = <span class="number">5</span>)</span><br><span class="line">search_params = dict(checks=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">flann = cv2.FlannBasedMatcher(index_params,search_params)</span><br><span class="line">matches = flann.knnMatch(des1,des2,k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">good = []</span><br><span class="line">pts1 = []</span><br><span class="line">pts2 = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># ratio test as per Lowe&#x27;s paper</span></span><br><span class="line"><span class="keyword">for</span> i,(m,n) <span class="keyword">in</span> enumerate(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.8</span>*n.distance:</span><br><span class="line">        good.append(m)</span><br><span class="line">        pts2.append(kp2[m.trainIdx].pt)</span><br><span class="line">        pts1.append(kp1[m.queryIdx].pt)</span><br><span class="line">pts1 = np.int32(pts1)</span><br><span class="line">pts2 = np.int32(pts2)</span><br><span class="line">F,mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># mask 是之前的对应点中的内点的标注，为1则是内点。</span></span><br><span class="line"><span class="comment"># select the inlier points</span></span><br><span class="line">pts1 = pts1[mask.ravel() == <span class="number">1</span>]</span><br><span class="line">pts2 = pts2[mask.ravel() == <span class="number">1</span>]</span><br><span class="line">self.match_pts1 = np.int32(pts1)</span><br><span class="line">self.match_pts2 = np.int32(pts2)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>由坐标估计基础矩阵：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> method == <span class="string">&quot;RANSAC&quot;</span>:</span><br><span class="line">    self.FE, self.Fmask = cv2.findFundamentalMat(self.match_pts1,</span><br><span class="line">                                            self.match_pts2,</span><br><span class="line">                                            cv2.FM_RANSAC, <span class="number">0.1</span>, <span class="number">0.99</span>)</span><br><span class="line"><span class="keyword">elif</span> method == <span class="string">&quot;LMedS&quot;</span>:</span><br><span class="line">    self.FE, self.Fmask = cv2.findFundamentalMat(self.match_pts1,</span><br><span class="line">                                            self.match_pts2,</span><br><span class="line">                                            cv2.FM_LMEDS, <span class="number">0.1</span>, <span class="number">0.99</span>)</span><br></pre></td></tr></table></figure>

<p>对于基础矩阵估计的精度，有两个评价标准以及一个可视化的方法。<br><strong>Metrics</strong><br><strong>1.对极几何约束</strong><br>根据对极几何，基础矩阵和两张图的对应点之间满足以下公式：<br>$xFx’=0$<br>所以通过计算这个式子，可以大致判断基础矩阵的精度。<br><strong>2.对极线距离</strong><br>基础矩阵描述的是左图的点到右图对应极线的变换，而且右图的对应点也应该在这条极线上。<br>通过计算，点到极线的距离，就可以大致评价基础矩阵的精度。  </p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">EpipolarConstraint</span>(<span class="params">self,F,pts1,pts2</span>):</span></span><br><span class="line">       <span class="string">&#x27;&#x27;&#x27;Epipolar Constraint</span></span><br><span class="line"><span class="string">           calculate the epipolar constraint </span></span><br><span class="line"><span class="string">           x^T*F*x</span></span><br><span class="line"><span class="string">           :output </span></span><br><span class="line"><span class="string">               err_permatch</span></span><br><span class="line"><span class="string">       &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">       print(<span class="string">&#x27;Use &#x27;</span>,len(pts1),<span class="string">&#x27; points to calculate epipolar constraints.&#x27;</span>)</span><br><span class="line">       <span class="keyword">assert</span> len(pts1) == len(pts2)</span><br><span class="line">       err = <span class="number">0.0</span></span><br><span class="line">       <span class="keyword">for</span> p1, p2 <span class="keyword">in</span> zip(pts1, pts2):</span><br><span class="line">           hp1, hp2 = np.ones((<span class="number">3</span>,<span class="number">1</span>)), np.ones((<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">           hp1[:<span class="number">2</span>,<span class="number">0</span>], hp2[:<span class="number">2</span>,<span class="number">0</span>] = p1, p2</span><br><span class="line">           err += np.abs(np.dot(hp2.T, np.dot(F, hp1)))</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> err / float(len(pts1))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">SymEpiDis</span>(<span class="params">self, F, pts1, pts2</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;Symetric Epipolar distance</span></span><br><span class="line"><span class="string">           calculate the Symetric Epipolar distance</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       epsilon = <span class="number">1e-5</span></span><br><span class="line">       <span class="keyword">assert</span> len(pts1) == len(pts2)</span><br><span class="line">       print(<span class="string">&#x27;Use &#x27;</span>,len(pts1),<span class="string">&#x27; points to calculate epipolar distance.&#x27;</span>)</span><br><span class="line">       err = <span class="number">0.</span></span><br><span class="line">       <span class="keyword">for</span> p1, p2 <span class="keyword">in</span> zip(pts1, pts2):</span><br><span class="line">           hp1, hp2 = np.ones((<span class="number">3</span>,<span class="number">1</span>)), np.ones((<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">           hp1[:<span class="number">2</span>,<span class="number">0</span>], hp2[:<span class="number">2</span>,<span class="number">0</span>] = p1, p2</span><br><span class="line">           fp, fq = np.dot(F, hp1), np.dot(F.T, hp2)</span><br><span class="line">           sym_jjt = <span class="number">1.</span>/(fp[<span class="number">0</span>]**<span class="number">2</span> + fp[<span class="number">1</span>]**<span class="number">2</span> + epsilon) + <span class="number">1.</span>/(fq[<span class="number">0</span>]**<span class="number">2</span> + fq[<span class="number">1</span>]**<span class="number">2</span> + epsilon)</span><br><span class="line">           err = err + ((np.dot(hp2.T, np.dot(F, hp1))**<span class="number">2</span>) * (sym_jjt + epsilon))</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> err / float(len(pts1))</span><br></pre></td></tr></table></figure>

<p><strong>可视化</strong><br>可视化是通过画出两张图上的对应点和极线来实现的。<br>因为极线会交于一点（极点），通过这个可以大致判断基础矩阵的精度。<br>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DrawEpipolarLines</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;For F Estimation visulization, drawing the epipolar lines</span></span><br><span class="line"><span class="string">        1. find epipolar lines</span></span><br><span class="line"><span class="string">        2. draw lines</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        self.FE.all()</span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        self.EstimateFM() <span class="comment"># use RANSAC as default</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        self.match_pts1.all()</span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        self.ExactGoodMatch()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Find epilines corresponding to points in right image (second image)</span></span><br><span class="line">    <span class="comment"># and drawing its lines on left image</span></span><br><span class="line">    pts2re = self.match_pts2.reshape(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    lines1 = cv2.computeCorrespondEpilines(pts2re, <span class="number">2</span>, self.FE)</span><br><span class="line">    lines1 = lines1.reshape(<span class="number">-1</span>, <span class="number">3</span>)</span><br><span class="line">    img3, img4 = self._draw_epipolar_lines_helper(self.imgl, self.imgr,</span><br><span class="line">                                                    lines1, self.match_pts1,</span><br><span class="line">                                                    self.match_pts2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Find epilines corresponding to points in left image (first image) and</span></span><br><span class="line">    <span class="comment"># drawing its lines on right image</span></span><br><span class="line">    pts1re = self.match_pts1.reshape(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    lines2 = cv2.computeCorrespondEpilines(pts1re, <span class="number">1</span>, self.FE)</span><br><span class="line">    lines2 = lines2.reshape(<span class="number">-1</span>, <span class="number">3</span>)</span><br><span class="line">    img1, img2 = self._draw_epipolar_lines_helper(self.imgr, self.imgl,</span><br><span class="line">                                                    lines2, self.match_pts2,</span><br><span class="line">                                                    self.match_pts1)</span><br><span class="line"></span><br><span class="line">    cv2.imwrite(os.path.join(self.SavePath,<span class="string">&quot;epipolarleft.jpg&quot;</span>),img1)</span><br><span class="line">    <span class="comment"># print(&quot;Saved in &quot;,os.path.join(self.SavePath,&quot;epipolarleft.jpg&quot;))</span></span><br><span class="line">    cv2.imwrite(os.path.join(self.SavePath,<span class="string">&quot;epipolarright.jpg&quot;</span>),img3)</span><br><span class="line"></span><br><span class="line">    cv2.startWindowThread()</span><br><span class="line">    cv2.imshow(<span class="string">&quot;left&quot;</span>, img1)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;right&quot;</span>, img3)</span><br><span class="line">    k = cv2.waitKey()</span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">27</span>:</span><br><span class="line">        cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="由基础矩阵分解本质矩阵"><a href="#由基础矩阵分解本质矩阵" class="headerlink" title="由基础矩阵分解本质矩阵"></a>由基础矩阵分解本质矩阵</h2><p>这一步用到的公式是：$E = Kl\times F\times Kr$<br>代码如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Get_Essential_Matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get Essential Matrix from Fundamental Matrix</span></span><br><span class="line"><span class="string">        E = Kl^T*F*Kr</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    self.E = self.Kl.T.dot(self.FE).dot(self.Kr)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="由本质矩阵分解得到相机矩阵-R-T"><a href="#由本质矩阵分解得到相机矩阵-R-T" class="headerlink" title="由本质矩阵分解得到相机矩阵[R|T]"></a>由本质矩阵分解得到相机矩阵[R|T]</h2><p>这里要用到SVD分解，并且要根据结果来测试四种可能性。具体原理可以去看<em>Multiple View Geometry in computer vision</em>.<br>代码如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Get_R_T</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the [R|T] camera matrix</span></span><br><span class="line"><span class="string">        After geting the R,T, need to determine whether the points are in front of the images</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># decompose essential matrix into R, t (See Hartley and Zisserman 9.13)</span></span><br><span class="line">    U, S, Vt = np.linalg.svd(self.E)</span><br><span class="line">    W = np.array([<span class="number">0.0</span>, <span class="number">-1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,</span><br><span class="line">                    <span class="number">1.0</span>]).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate over all point correspondences used in the estimation of the</span></span><br><span class="line">    <span class="comment"># fundamental matrix</span></span><br><span class="line">    first_inliers = []</span><br><span class="line">    second_inliers = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.Fmask)):</span><br><span class="line">        <span class="keyword">if</span> self.Fmask[i]:</span><br><span class="line">            <span class="comment"># normalize and homogenize the image coordinates</span></span><br><span class="line">            first_inliers.append(self.Kl_inv.dot([self.match_pts1[i][<span class="number">0</span>],</span><br><span class="line">                                    self.match_pts1[i][<span class="number">1</span>], <span class="number">1.0</span>]))</span><br><span class="line">            second_inliers.append(self.Kr_inv.dot([self.match_pts2[i][<span class="number">0</span>],</span><br><span class="line">                                    self.match_pts2[i][<span class="number">1</span>], <span class="number">1.0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Determine the correct choice of second camera matrix</span></span><br><span class="line">    <span class="comment"># only in one of the four configurations will all the points be in</span></span><br><span class="line">    <span class="comment"># front of both cameras</span></span><br><span class="line">    <span class="comment"># First choice: R = U * Wt * Vt, T = +u_3 (See Hartley Zisserman 9.19)</span></span><br><span class="line">    R = U.dot(W).dot(Vt)</span><br><span class="line">    T = U[:, <span class="number">2</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self._in_front_of_both_cameras(first_inliers, second_inliers,</span><br><span class="line">                                            R, T):</span><br><span class="line">        <span class="comment"># Second choice: R = U * W * Vt, T = -u_3</span></span><br><span class="line">        T = - U[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self._in_front_of_both_cameras(first_inliers, second_inliers,</span><br><span class="line">                                            R, T):</span><br><span class="line">        <span class="comment"># Third choice: R = U * Wt * Vt, T = u_3</span></span><br><span class="line">        R = U.dot(W.T).dot(Vt)</span><br><span class="line">        T = U[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._in_front_of_both_cameras(first_inliers,</span><br><span class="line">                                                second_inliers, R, T):</span><br><span class="line">            <span class="comment"># Fourth choice: R = U * Wt * Vt, T = -u_3</span></span><br><span class="line">            T = - U[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    self.match_inliers1 = first_inliers</span><br><span class="line">    self.match_inliers2 = second_inliers</span><br><span class="line">    self.Rt1 = np.hstack((np.eye(<span class="number">3</span>), np.zeros((<span class="number">3</span>, <span class="number">1</span>)))) <span class="comment"># as defaluted RT </span></span><br><span class="line">    self.Rt2 = np.hstack((R, T.reshape(<span class="number">3</span>, <span class="number">1</span>)))</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="图片校正"><a href="#图片校正" class="headerlink" title="图片校正"></a>图片校正</h2><p>这里我提供了两种校正的算法。<br>一种是要用到之前的相机参数实现的校正，依赖于cv2.stereoRectify()<br>都是固有流程，原理见<em>Multiple View Geometry in computer vision</em><br>代码如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">RectifyImg</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Rectify images using cv2.stereoRectify()</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        self.FE.all()</span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        self.EstimateFM() <span class="comment"># Using traditional method as default</span></span><br><span class="line"></span><br><span class="line">    self._Get_Essential_Matrix()</span><br><span class="line">    self._Get_R_T()</span><br><span class="line"></span><br><span class="line">    R = self.Rt2[:, :<span class="number">3</span>]</span><br><span class="line">    T = self.Rt2[:, <span class="number">3</span>]</span><br><span class="line">    <span class="comment">#perform the rectification</span></span><br><span class="line">    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(self.Kl, self.dl,</span><br><span class="line">                                                        self.Kr, self.dr,</span><br><span class="line">                                                        self.imgl.shape[:<span class="number">2</span>],</span><br><span class="line">                                                        R, T, alpha=<span class="number">0</span>)</span><br><span class="line">    mapx1, mapy1 = cv2.initUndistortRectifyMap(self.Kl, self.dl, R1, P1,</span><br><span class="line">                                                [self.imgl.shape[<span class="number">0</span>],self.imgl.shape[<span class="number">1</span>]],</span><br><span class="line">                                                cv2.CV_32FC1)</span><br><span class="line">    mapx2, mapy2 = cv2.initUndistortRectifyMap(self.Kr, self.dr, R2, P2,</span><br><span class="line">                                                [self.imgl.shape[<span class="number">0</span>],self.imgl.shape[<span class="number">1</span>]],</span><br><span class="line">                                                cv2.CV_32FC1)</span><br><span class="line">    img_rect1 = cv2.remap(self.imgl, mapx1, mapy1, cv2.INTER_LINEAR)</span><br><span class="line">    img_rect2 = cv2.remap(self.imgr, mapx2, mapy2, cv2.INTER_LINEAR)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># save</span></span><br><span class="line">    cv2.imwrite(os.path.join(self.SavePath,<span class="string">&quot;RectedLeft.jpg&quot;</span>),img_rect1)</span><br><span class="line">    cv2.imwrite(os.path.join(self.SavePath,<span class="string">&quot;RectedRight.jpg&quot;</span>),img_rect2)</span><br></pre></td></tr></table></figure>

<p>另外一种是不需要相机内参的校正算法，依赖于cv2.stereoRectifyUncalibrated()<br>代码如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">returnH1_H2</span>(<span class="params">points1,points2,F,size</span>):</span></span><br><span class="line">    p1=points1.reshape(len(points1)*<span class="number">2</span>,<span class="number">1</span>)<span class="comment">#stackoverflow上需要将(m,2)的点变为(m*2,1),因为不变在c++中会产生内存溢出</span></span><br><span class="line">    p2=points2.reshape(len(points2)*<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    _,H1,H2=cv2.stereoRectifyUncalibrated(p1,p2,F,size) <span class="comment">#size是宽，高</span></span><br><span class="line">    <span class="keyword">return</span> H1,H2</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="结果及说明"><a href="#结果及说明" class="headerlink" title="结果及说明"></a>结果及说明</h2><p>校正前：<br><img   class="lazyload" data-original="https://img-blog.csdnimg.cn/20200205151923511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjczMDk5Nw==,size_16,color_FFFFFF,t_70" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  alt="Oringinal Left"><br><img   class="lazyload" data-original="https://img-blog.csdnimg.cn/20200205151909275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjczMDk5Nw==,size_16,color_FFFFFF,t_70" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  alt="Oringinal Right"></p>
<p>校正后：<br><img   class="lazyload" data-original="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL0Vhc29ueWVzaGVuZy9NYXJrZG93blBpY3R1cmVzL21hc3Rlci9SZWN0VW5jYWxpYkxlZnQuanBn?x-oss-process=image/format,png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  alt="Rectifyed Left"><br><img   class="lazyload" data-original="https://img-blog.csdnimg.cn/20200205151838386.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjczMDk5Nw==,size_16,color_FFFFFF,t_70" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  alt="Rectifyed Right"></p>
<p>完整的代码在我的GitHub<a target="_blank" rel="noopener" href="https://github.com/Easonyesheng/StereoCamera">项目</a>中有，记得给个Star。<br><em>中国人喜欢折中。如果你告诉他们不要白嫖，他们往往偏要看了用了不Star，如果你告诉他们给钱才能看才能用，他们就会Star来代替给钱。 – 周树人</em>  </p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">    st=>start: Load Dataset
    op1=>operation: Estimate Fundamental matrix
    op2=>operation: Get essential matrix
    op3=>operation: Get camera matrix[R t]
    op4=>operation: Rectify Images
    ed=>end: Output Images
    st->op1->op2->op3->op4->ed</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script>
    </section>
    <section class="extra">
      
        <ul class="copyright">
  
  <li><strong>本文作者：</strong>Eason Zhang</li>
  <li><strong>本文链接：</strong><a href="http://northpointer.xyz/2020/08/13/Python-%E5%8F%8C%E7%9B%AE%E8%87%AA%E6%A0%87%E5%AE%9A%E7%B3%BB%E7%BB%9F/index.html">http://northpointer.xyz/2020/08/13/Python-%E5%8F%8C%E7%9B%AE%E8%87%AA%E6%A0%87%E5%AE%9A%E7%B3%BB%E7%BB%9F/index.html</a></li>
  <li><strong>版权声明：</strong>本博客所有文章均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"
      rel="external nofollow" target="_blank"> BY-NC-SA </a>许可协议，转载请注明出处！</li>
  
</ul>
      
      
      
  <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%8C%E7%9B%AE%E8%A7%86%E8%A7%89/" rel="tag">双目视觉</a></li></ul>

      
<nav class="nav">
  
  
    <a href="/2020/08/13/DIP4/">数字图像处理总结4<i class="iconfont iconright"></i></a>
  
</nav>

    </section>
    
  </section>
</article>
  </div>
</main>
  <footer class="footer">
  <div class="footer-social">
    
    
    
    
    
    <a href="https://github.com/Easonyesheng " target="_blank" onMouseOver="this.style.color= '#24292E'"
      onMouseOut="this.style.color='#33333D'">
      <i class="iconfont footer-social-item  icongithub-fill "></i>
    </a>
    
    
    
    
    
    <a href="mailto:preacher@sjtu.edu.cn " target="_blank" onMouseOver="this.style.color='#FFBE5B'"
      onMouseOut="this.style.color='#33333D'">
      <i class="iconfont footer-social-item  iconmail"></i>
    </a>
    
  </div>
  <div class="footer-copyright"><p>Copyright© 2019-2020 | <a target="_blank" href="https://northpointer.xyz">zhaoo</a> .AllRightsReserved</p></div>
</footer>
  
      <div class="fab fab-plus">
    <i class="iconfont iconplus"></i>
  </div>
  
  <div class="fab fab-daovoice">
    <i class="iconfont iconcomment"></i>
  </div>
  
  <div class="fab fab-up">
    <i class="iconfont iconcaret-up"></i>
  </div>
  <div class="fab fab-menu">
    <i class="iconfont iconmenu"></i>
  </div>
  
</body>


<script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script>






<script src="https://cdn.bootcdn.net/ajax/libs/jquery.lazyload/1.9.1/jquery.lazyload.min.js"></script>








<script src="https://cdn.bootcss.com/fancybox/3.5.7/jquery.fancybox.min.js"></script>






<script src="/js/utils.js"></script>
<script src="/js/zui.js"></script>
<script src="/js/script.js"></script>





<script defer>
  (function (i, s, o, g, r, a, m) {
    i["DaoVoiceObject"] = r;
    i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date();
    a = s.createElement(o), m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    a.charset = "utf-8";
    m.parentNode.insertBefore(a, m)
  })(window, document, "script", ('https:' == document.location.protocol ? 'https:' : 'http:') +
    "//widget.daovoice.io/widget/0f81ff2f.js", "daovoice")
  daovoice('init', {
    app_id: "abcdefg"
  }, {
    launcher: {
      disableLauncherIcon: true,
    },
  });
  daovoice('update');
</script>



<script defer>
  (function () {
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
      bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    } else {
      bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
  })();
</script>











</html>