<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>指北集</title>
  
  <subtitle>二十一世纪漫游指北</subtitle>
  <link href="http://yoursite.com/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-08-13T08:12:22.127Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Eason Zhang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python实现的双目相机自标定系统</title>
    <link href="http://yoursite.com/2020/08/13/Python-%E5%8F%8C%E7%9B%AE%E8%87%AA%E6%A0%87%E5%AE%9A%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2020/08/13/Python-%E5%8F%8C%E7%9B%AE%E8%87%AA%E6%A0%87%E5%AE%9A%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-08-13T07:48:08.000Z</published>
    <updated>2020-08-13T08:12:22.127Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python实现的双目相机自标定系统"><a href="#Python实现的双目相机自标定系统" class="headerlink" title="Python实现的双目相机自标定系统"></a>Python实现的双目相机自标定系统</h1><hr><h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><p>python-opencv 3.14<br>numpy<br>os<br>sys  </p><hr><h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><p>···flow<br>    st=&gt;start: Load Dataset<br>    op1=&gt;operation: Estimate Fundamental matrix<br>    op2=&gt;operation: Get essential matrix<br>    op3=&gt;operation: Get camera matrix[R t]<br>    op4=&gt;operation: Rectify Images<br>    ed=&gt;end: Output Images<br>    st-&gt;op1-&gt;op2-&gt;op3-&gt;op4-&gt;ed<br>···</p><hr><h2 id="读入图片和参数"><a href="#读入图片和参数" class="headerlink" title="读入图片和参数"></a>读入图片和参数</h2><p>图片是使用常规的imread，重点是参数的读取。<br>这里选取的参数是kitti的标定文件，读取方式如下：  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Paser</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Paser the calib_file </span></span><br><span class="line"><span class="string">    return a dictionary</span></span><br><span class="line"><span class="string">    use it as :</span></span><br><span class="line"><span class="string">        calib = self.Paser()</span></span><br><span class="line"><span class="string">        K1, K2 = self.calib[&#x27;K_0&#123;&#125;&#x27;.format(f_cam)], self.calib[&#x27;K_0&#123;&#125;&#x27;.format(t_cam)]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    d = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> open(self.calib_path) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> f:</span><br><span class="line">            <span class="keyword">if</span> l.startswith(<span class="string">&quot;calib_time&quot;</span>):</span><br><span class="line">                d[<span class="string">&quot;calib_time&quot;</span>] = l[l.index(<span class="string">&quot;calib_time&quot;</span>)+<span class="number">1</span>:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                [k,v] = l.split(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">                k,v = k.strip(), v.strip()</span><br><span class="line">                <span class="comment">#get the numbers out</span></span><br><span class="line">                v = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> v.strip().split(<span class="string">&quot; &quot;</span>)]</span><br><span class="line">                v = np.array(v)</span><br><span class="line">                <span class="keyword">if</span> len(v) == <span class="number">9</span>:</span><br><span class="line">                    v = v.reshape((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">                <span class="keyword">elif</span> len(v) == <span class="number">3</span>:</span><br><span class="line">                    v = v.reshape((<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">                <span class="keyword">elif</span> len(v) == <span class="number">5</span>:</span><br><span class="line">                    v = v.reshape((<span class="number">5</span>,<span class="number">1</span>))</span><br><span class="line">                d[k] = v</span><br><span class="line">    <span class="keyword">return</span> d</span><br></pre></td></tr></table></figure><hr><h2 id="估计基础矩阵"><a href="#估计基础矩阵" class="headerlink" title="估计基础矩阵"></a>估计基础矩阵</h2><p>基础矩阵的估计采用的是传统的算法，可选的是<strong>SIFT+RANSAC</strong>和<strong>SIFT+LMedS</strong>。<br>关键代码如下：  </p><p>提取特征点算法SIFT:  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"></span><br><span class="line"><span class="comment"># find the keypoints and descriptors with SIFT</span></span><br><span class="line">kp1, des1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">kp2, des2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># FLANN parameters</span></span><br><span class="line">FLANN_INDEX_KDTREE = <span class="number">0</span></span><br><span class="line">index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = <span class="number">5</span>)</span><br><span class="line">search_params = dict(checks=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">flann = cv2.FlannBasedMatcher(index_params,search_params)</span><br><span class="line">matches = flann.knnMatch(des1,des2,k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">good = []</span><br><span class="line">pts1 = []</span><br><span class="line">pts2 = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># ratio test as per Lowe&#x27;s paper</span></span><br><span class="line"><span class="keyword">for</span> i,(m,n) <span class="keyword">in</span> enumerate(matches):</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.8</span>*n.distance:</span><br><span class="line">        good.append(m)</span><br><span class="line">        pts2.append(kp2[m.trainIdx].pt)</span><br><span class="line">        pts1.append(kp1[m.queryIdx].pt)</span><br><span class="line">pts1 = np.int32(pts1)</span><br><span class="line">pts2 = np.int32(pts2)</span><br><span class="line">F,mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># mask 是之前的对应点中的内点的标注，为1则是内点。</span></span><br><span class="line"><span class="comment"># select the inlier points</span></span><br><span class="line">pts1 = pts1[mask.ravel() == <span class="number">1</span>]</span><br><span class="line">pts2 = pts2[mask.ravel() == <span class="number">1</span>]</span><br><span class="line">self.match_pts1 = np.int32(pts1)</span><br><span class="line">self.match_pts2 = np.int32(pts2)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>由坐标估计基础矩阵：  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> method == <span class="string">&quot;RANSAC&quot;</span>:</span><br><span class="line">    self.FE, self.Fmask = cv2.findFundamentalMat(self.match_pts1,</span><br><span class="line">                                            self.match_pts2,</span><br><span class="line">                                            cv2.FM_RANSAC, <span class="number">0.1</span>, <span class="number">0.99</span>)</span><br><span class="line"><span class="keyword">elif</span> method == <span class="string">&quot;LMedS&quot;</span>:</span><br><span class="line">    self.FE, self.Fmask = cv2.findFundamentalMat(self.match_pts1,</span><br><span class="line">                                            self.match_pts2,</span><br><span class="line">                                            cv2.FM_LMEDS, <span class="number">0.1</span>, <span class="number">0.99</span>)</span><br></pre></td></tr></table></figure><p>对于基础矩阵估计的精度，有两个评价标准以及一个可视化的方法。<br><strong>Metrics</strong><br><strong>1.对极几何约束</strong><br>根据对极几何，基础矩阵和两张图的对应点之间满足以下公式：<br>$xFx’=0$<br>所以通过计算这个式子，可以大致判断基础矩阵的精度。<br><strong>2.对极线距离</strong><br>基础矩阵描述的是左图的点到右图对应极线的变换，而且右图的对应点也应该在这条极线上。<br>通过计算，点到极线的距离，就可以大致评价基础矩阵的精度。  </p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">EpipolarConstraint</span>(<span class="params">self,F,pts1,pts2</span>):</span></span><br><span class="line">       <span class="string">&#x27;&#x27;&#x27;Epipolar Constraint</span></span><br><span class="line"><span class="string">           calculate the epipolar constraint </span></span><br><span class="line"><span class="string">           x^T*F*x</span></span><br><span class="line"><span class="string">           :output </span></span><br><span class="line"><span class="string">               err_permatch</span></span><br><span class="line"><span class="string">       &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">       print(<span class="string">&#x27;Use &#x27;</span>,len(pts1),<span class="string">&#x27; points to calculate epipolar constraints.&#x27;</span>)</span><br><span class="line">       <span class="keyword">assert</span> len(pts1) == len(pts2)</span><br><span class="line">       err = <span class="number">0.0</span></span><br><span class="line">       <span class="keyword">for</span> p1, p2 <span class="keyword">in</span> zip(pts1, pts2):</span><br><span class="line">           hp1, hp2 = np.ones((<span class="number">3</span>,<span class="number">1</span>)), np.ones((<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">           hp1[:<span class="number">2</span>,<span class="number">0</span>], hp2[:<span class="number">2</span>,<span class="number">0</span>] = p1, p2</span><br><span class="line">           err += np.abs(np.dot(hp2.T, np.dot(F, hp1)))</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> err / float(len(pts1))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">SymEpiDis</span>(<span class="params">self, F, pts1, pts2</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;Symetric Epipolar distance</span></span><br><span class="line"><span class="string">           calculate the Symetric Epipolar distance</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       epsilon = <span class="number">1e-5</span></span><br><span class="line">       <span class="keyword">assert</span> len(pts1) == len(pts2)</span><br><span class="line">       print(<span class="string">&#x27;Use &#x27;</span>,len(pts1),<span class="string">&#x27; points to calculate epipolar distance.&#x27;</span>)</span><br><span class="line">       err = <span class="number">0.</span></span><br><span class="line">       <span class="keyword">for</span> p1, p2 <span class="keyword">in</span> zip(pts1, pts2):</span><br><span class="line">           hp1, hp2 = np.ones((<span class="number">3</span>,<span class="number">1</span>)), np.ones((<span class="number">3</span>,<span class="number">1</span>))</span><br><span class="line">           hp1[:<span class="number">2</span>,<span class="number">0</span>], hp2[:<span class="number">2</span>,<span class="number">0</span>] = p1, p2</span><br><span class="line">           fp, fq = np.dot(F, hp1), np.dot(F.T, hp2)</span><br><span class="line">           sym_jjt = <span class="number">1.</span>/(fp[<span class="number">0</span>]**<span class="number">2</span> + fp[<span class="number">1</span>]**<span class="number">2</span> + epsilon) + <span class="number">1.</span>/(fq[<span class="number">0</span>]**<span class="number">2</span> + fq[<span class="number">1</span>]**<span class="number">2</span> + epsilon)</span><br><span class="line">           err = err + ((np.dot(hp2.T, np.dot(F, hp1))**<span class="number">2</span>) * (sym_jjt + epsilon))</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> err / float(len(pts1))</span><br></pre></td></tr></table></figure><p><strong>可视化</strong><br>可视化是通过画出两张图上的对应点和极线来实现的。<br>因为极线会交于一点（极点），通过这个可以大致判断基础矩阵的精度。<br>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DrawEpipolarLines</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;For F Estimation visulization, drawing the epipolar lines</span></span><br><span class="line"><span class="string">        1. find epipolar lines</span></span><br><span class="line"><span class="string">        2. draw lines</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        self.FE.all()</span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        self.EstimateFM() <span class="comment"># use RANSAC as default</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        self.match_pts1.all()</span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        self.ExactGoodMatch()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Find epilines corresponding to points in right image (second image)</span></span><br><span class="line">    <span class="comment"># and drawing its lines on left image</span></span><br><span class="line">    pts2re = self.match_pts2.reshape(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    lines1 = cv2.computeCorrespondEpilines(pts2re, <span class="number">2</span>, self.FE)</span><br><span class="line">    lines1 = lines1.reshape(<span class="number">-1</span>, <span class="number">3</span>)</span><br><span class="line">    img3, img4 = self._draw_epipolar_lines_helper(self.imgl, self.imgr,</span><br><span class="line">                                                    lines1, self.match_pts1,</span><br><span class="line">                                                    self.match_pts2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Find epilines corresponding to points in left image (first image) and</span></span><br><span class="line">    <span class="comment"># drawing its lines on right image</span></span><br><span class="line">    pts1re = self.match_pts1.reshape(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    lines2 = cv2.computeCorrespondEpilines(pts1re, <span class="number">1</span>, self.FE)</span><br><span class="line">    lines2 = lines2.reshape(<span class="number">-1</span>, <span class="number">3</span>)</span><br><span class="line">    img1, img2 = self._draw_epipolar_lines_helper(self.imgr, self.imgl,</span><br><span class="line">                                                    lines2, self.match_pts2,</span><br><span class="line">                                                    self.match_pts1)</span><br><span class="line"></span><br><span class="line">    cv2.imwrite(os.path.join(self.SavePath,<span class="string">&quot;epipolarleft.jpg&quot;</span>),img1)</span><br><span class="line">    <span class="comment"># print(&quot;Saved in &quot;,os.path.join(self.SavePath,&quot;epipolarleft.jpg&quot;))</span></span><br><span class="line">    cv2.imwrite(os.path.join(self.SavePath,<span class="string">&quot;epipolarright.jpg&quot;</span>),img3)</span><br><span class="line"></span><br><span class="line">    cv2.startWindowThread()</span><br><span class="line">    cv2.imshow(<span class="string">&quot;left&quot;</span>, img1)</span><br><span class="line">    cv2.imshow(<span class="string">&quot;right&quot;</span>, img3)</span><br><span class="line">    k = cv2.waitKey()</span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">27</span>:</span><br><span class="line">        cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><hr><h2 id="由基础矩阵分解本质矩阵"><a href="#由基础矩阵分解本质矩阵" class="headerlink" title="由基础矩阵分解本质矩阵"></a>由基础矩阵分解本质矩阵</h2><p>这一步用到的公式是：$E = Kl\times F\times Kr$<br>代码如下：  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Get_Essential_Matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get Essential Matrix from Fundamental Matrix</span></span><br><span class="line"><span class="string">        E = Kl^T*F*Kr</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    self.E = self.Kl.T.dot(self.FE).dot(self.Kr)</span><br></pre></td></tr></table></figure><hr><h2 id="由本质矩阵分解得到相机矩阵-R-T"><a href="#由本质矩阵分解得到相机矩阵-R-T" class="headerlink" title="由本质矩阵分解得到相机矩阵[R|T]"></a>由本质矩阵分解得到相机矩阵[R|T]</h2><p>这里要用到SVD分解，并且要根据结果来测试四种可能性。具体原理可以去看<em>Multiple View Geometry in computer vision</em>.<br>代码如下：  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_Get_R_T</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the [R|T] camera matrix</span></span><br><span class="line"><span class="string">        After geting the R,T, need to determine whether the points are in front of the images</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># decompose essential matrix into R, t (See Hartley and Zisserman 9.13)</span></span><br><span class="line">    U, S, Vt = np.linalg.svd(self.E)</span><br><span class="line">    W = np.array([<span class="number">0.0</span>, <span class="number">-1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,</span><br><span class="line">                    <span class="number">1.0</span>]).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate over all point correspondences used in the estimation of the</span></span><br><span class="line">    <span class="comment"># fundamental matrix</span></span><br><span class="line">    first_inliers = []</span><br><span class="line">    second_inliers = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.Fmask)):</span><br><span class="line">        <span class="keyword">if</span> self.Fmask[i]:</span><br><span class="line">            <span class="comment"># normalize and homogenize the image coordinates</span></span><br><span class="line">            first_inliers.append(self.Kl_inv.dot([self.match_pts1[i][<span class="number">0</span>],</span><br><span class="line">                                    self.match_pts1[i][<span class="number">1</span>], <span class="number">1.0</span>]))</span><br><span class="line">            second_inliers.append(self.Kr_inv.dot([self.match_pts2[i][<span class="number">0</span>],</span><br><span class="line">                                    self.match_pts2[i][<span class="number">1</span>], <span class="number">1.0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Determine the correct choice of second camera matrix</span></span><br><span class="line">    <span class="comment"># only in one of the four configurations will all the points be in</span></span><br><span class="line">    <span class="comment"># front of both cameras</span></span><br><span class="line">    <span class="comment"># First choice: R = U * Wt * Vt, T = +u_3 (See Hartley Zisserman 9.19)</span></span><br><span class="line">    R = U.dot(W).dot(Vt)</span><br><span class="line">    T = U[:, <span class="number">2</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self._in_front_of_both_cameras(first_inliers, second_inliers,</span><br><span class="line">                                            R, T):</span><br><span class="line">        <span class="comment"># Second choice: R = U * W * Vt, T = -u_3</span></span><br><span class="line">        T = - U[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> self._in_front_of_both_cameras(first_inliers, second_inliers,</span><br><span class="line">                                            R, T):</span><br><span class="line">        <span class="comment"># Third choice: R = U * Wt * Vt, T = u_3</span></span><br><span class="line">        R = U.dot(W.T).dot(Vt)</span><br><span class="line">        T = U[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._in_front_of_both_cameras(first_inliers,</span><br><span class="line">                                                second_inliers, R, T):</span><br><span class="line">            <span class="comment"># Fourth choice: R = U * Wt * Vt, T = -u_3</span></span><br><span class="line">            T = - U[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    self.match_inliers1 = first_inliers</span><br><span class="line">    self.match_inliers2 = second_inliers</span><br><span class="line">    self.Rt1 = np.hstack((np.eye(<span class="number">3</span>), np.zeros((<span class="number">3</span>, <span class="number">1</span>)))) <span class="comment"># as defaluted RT </span></span><br><span class="line">    self.Rt2 = np.hstack((R, T.reshape(<span class="number">3</span>, <span class="number">1</span>)))</span><br></pre></td></tr></table></figure><hr><h2 id="图片校正"><a href="#图片校正" class="headerlink" title="图片校正"></a>图片校正</h2><p>这里我提供了两种校正的算法。<br>一种是要用到之前的相机参数实现的校正，依赖于cv2.stereoRectify()<br>都是固有流程，原理见<em>Multiple View Geometry in computer vision</em><br>代码如下：  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">RectifyImg</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Rectify images using cv2.stereoRectify()</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        self.FE.all()</span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        self.EstimateFM() <span class="comment"># Using traditional method as default</span></span><br><span class="line"></span><br><span class="line">    self._Get_Essential_Matrix()</span><br><span class="line">    self._Get_R_T()</span><br><span class="line"></span><br><span class="line">    R = self.Rt2[:, :<span class="number">3</span>]</span><br><span class="line">    T = self.Rt2[:, <span class="number">3</span>]</span><br><span class="line">    <span class="comment">#perform the rectification</span></span><br><span class="line">    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(self.Kl, self.dl,</span><br><span class="line">                                                        self.Kr, self.dr,</span><br><span class="line">                                                        self.imgl.shape[:<span class="number">2</span>],</span><br><span class="line">                                                        R, T, alpha=<span class="number">0</span>)</span><br><span class="line">    mapx1, mapy1 = cv2.initUndistortRectifyMap(self.Kl, self.dl, R1, P1,</span><br><span class="line">                                                [self.imgl.shape[<span class="number">0</span>],self.imgl.shape[<span class="number">1</span>]],</span><br><span class="line">                                                cv2.CV_32FC1)</span><br><span class="line">    mapx2, mapy2 = cv2.initUndistortRectifyMap(self.Kr, self.dr, R2, P2,</span><br><span class="line">                                                [self.imgl.shape[<span class="number">0</span>],self.imgl.shape[<span class="number">1</span>]],</span><br><span class="line">                                                cv2.CV_32FC1)</span><br><span class="line">    img_rect1 = cv2.remap(self.imgl, mapx1, mapy1, cv2.INTER_LINEAR)</span><br><span class="line">    img_rect2 = cv2.remap(self.imgr, mapx2, mapy2, cv2.INTER_LINEAR)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># save</span></span><br><span class="line">    cv2.imwrite(os.path.join(self.SavePath,<span class="string">&quot;RectedLeft.jpg&quot;</span>),img_rect1)</span><br><span class="line">    cv2.imwrite(os.path.join(self.SavePath,<span class="string">&quot;RectedRight.jpg&quot;</span>),img_rect2)</span><br></pre></td></tr></table></figure><p>另外一种是不需要相机内参的校正算法，依赖于cv2.stereoRectifyUncalibrated()<br>代码如下：  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">returnH1_H2</span>(<span class="params">points1,points2,F,size</span>):</span></span><br><span class="line">    p1=points1.reshape(len(points1)*<span class="number">2</span>,<span class="number">1</span>)<span class="comment">#stackoverflow上需要将(m,2)的点变为(m*2,1),因为不变在c++中会产生内存溢出</span></span><br><span class="line">    p2=points2.reshape(len(points2)*<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    _,H1,H2=cv2.stereoRectifyUncalibrated(p1,p2,F,size) <span class="comment">#size是宽，高</span></span><br><span class="line">    <span class="keyword">return</span> H1,H2</span><br></pre></td></tr></table></figure><hr><h2 id="结果及说明"><a href="#结果及说明" class="headerlink" title="结果及说明"></a>结果及说明</h2><p>校正前：<br><img src="https://github.com/Easonyesheng/MarkdownPictures/raw/master/left.jpg" alt="Oringinal Left"><br><img src="https://github.com/Easonyesheng/MarkdownPictures/raw/master/right.jpg" alt="Oringinal Right"></p><p>校正后：<br><img src="https://github.com/Easonyesheng/MarkdownPictures/blob/master/RectUncalibLeft.jpg" alt="Rectifyed Left"><br><img src="https://github.com/Easonyesheng/MarkdownPictures/raw/master/RectUncalibRight.jpg" alt="Rectifyed Right"></p><p>完整的代码在我的GitHub<a href="https://github.com/Easonyesheng/StereoCamera">项目</a>中有，记得给个Star。<br><em>中国人喜欢折中。如果你告诉他们不要白嫖，他们往往偏要看了用了不Star，如果你告诉他们给钱才能看才能用，他们就会Star来代替给钱。 – 周树人</em>  </p>]]></content>
    
    
    <summary type="html">基于opencv。</summary>
    
    
    
    
    <category term="双目视觉" scheme="http://yoursite.com/tags/%E5%8F%8C%E7%9B%AE%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>数字图像处理总结4</title>
    <link href="http://yoursite.com/2020/08/13/DIP4/"/>
    <id>http://yoursite.com/2020/08/13/DIP4/</id>
    <published>2020-08-13T06:43:46.000Z</published>
    <updated>2020-08-13T06:51:45.563Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图像处理总结4"><a href="#图像处理总结4" class="headerlink" title="图像处理总结4"></a>图像处理总结4</h1><p>灰度形态学<br>之前说过：<br><strong>形态学起源于法国巴黎高等矿业学院，因为人家是搞地质的。</strong><br><strong>可见一斑，形态学的精要就是在于将图像看作是等高线组成的地形图，他的基本操作就是动土，平高填低等等。</strong><br>之前的二值形态学针对的是二值图片，在地形上，就像是现代的建筑，拔地而起没有一定的梯度。<br>而这篇是针对灰度图片的形态学，这时的图片就更像自然界的地貌，像山川，像河谷。  </p><hr><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><p>基本操作也是腐蚀和膨胀。<br><strong>Dilation（膨胀）：</strong><br>先看公式：$F\bigoplus k=max_{a,b\in k}{F(x-a,y-b)+k(a,b)}$<br>同样有两种算法。<br>1）平移<br>对原图先加上SE对应部分的值，再向SE对应的位置平移，然后取最大值。<br>比如，现在有一个一维的SE: [1,2,3], 中心点定为第一个点，就是“1”。<br>那么首先对应于“1”，则是原图位置不变加1.<br>对于“2”，原图灰度值加2，向右平移一位。<br>对于“3”，原图灰度值加3，向右平移两位。<br>最后将三张图重合，并在原图区域取最大值，作为结果图。<br>2）盖章<br>SE在原图上滑动，每个滑动的位置，SE与原图相加，中心点取SE范围内最大值作为结果。<br>这个程序上好实现。<br>==直观上，就是原图亮的地方会更亮（整体亮度增加），且范围扩大。==<br><strong>Erosion（腐蚀）：</strong><br>公式：$F\bigodot k=min_{a,b \in k}{F(x-a,y-b)-k(a,b)}$<br>与膨胀不同的就是与SE相减，取最小值。<br>==直观上就是，暗的地方会更暗（整体亮度减小）==<br><strong>Open（开）：</strong><br>先腐蚀后膨胀。<br>==直观上就是消除了原图上比SE小的亮处。==<br><strong>Close（闭）：</strong><br>先膨胀后腐蚀。<br>==直观上与Open相反，消除了暗处。==  </p><hr><h2 id="组合算法"><a href="#组合算法" class="headerlink" title="组合算法"></a>组合算法</h2><p><strong>TopHat Transform:</strong><br>高帽变换分为白色高帽变换和黑色高帽变换。<br>白色是指将灰度Close过的图和原图相减。<br>黑色是指将原图与灰度Open过的图相减。<br>总之就是留下了灰度形态学操作突出的部分。  </p><p><strong>Grayscale Reconstruction:</strong><br>灰度重建分为OBR和CBR。<br>一个是针对Open后的图片重建。<br>一个是针对Close后的图片重建。<br>重建算法就是不断膨胀，但每次膨胀后与原图比较，将灰度值高于原图处的点置为原图的灰度值。<br>意思就是不能超过原图的灰度值。重复膨胀直到稳定。<br>==类似二值里面的Conditional Dilation==</p><p><strong>梯度：</strong><br>灰度形态学也有梯度，和二值里面的相同。  </p><hr><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>这里的算法都可以在我的GitHub里的<a href="https://github.com/Easonyesheng/DIP_GUI">项目</a>里找到<br>包括灰度形态学基本操作（D，E，O，C），以及部分组合算法。<br>该项目是一个包括阈值分割、卷积滤波、形态学和灰度形态学的数字图像处理算法集合<br>用法见readme文件。<br>且带有GUI，有很好的演示效果<br>觉得可以别忘了star哦  </p>]]></content>
    
    
    <summary type="html">灰度形态学。</summary>
    
    
    
    
    <category term="数字图像处理" scheme="http://yoursite.com/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>数字图像处理总结3</title>
    <link href="http://yoursite.com/2020/08/13/DIP3/"/>
    <id>http://yoursite.com/2020/08/13/DIP3/</id>
    <published>2020-08-13T06:42:02.000Z</published>
    <updated>2020-08-13T06:51:32.301Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图像处理总结3"><a href="#图像处理总结3" class="headerlink" title="图像处理总结3"></a>图像处理总结3</h1><p>二值形态学<br><strong>形态学起源于法国巴黎高等矿业学院，因为人家是搞地质的。</strong><br><strong>可见一斑，形态学的精要就是在于将图像看作是等高线组成的地形图，他的基本操作就是动土，平高填低等等。</strong><br>当然，这是哲学层面的抽象概念，太玄，还是整点实际的。<br>==需要注意的是，这里处理的图片都是二值图片（0 or 1）。==  </p><hr><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><p><strong>结构元素（SE）</strong><br>就是你要动土的那块地方多大，以及要怎么动土。  </p><p><strong>腐蚀（Erosion）：</strong><br>先看公式：$E(F,k)=F\bigodot k=\bigcap ({ a+b|a \in F})$<br>F：原图，k：SE<br>这里就有两种看法。<br>第一种，核心：<em>平移</em><br>原图按照结构元素平移，在原图大小里取交集。<br>这里要关心SE的中心在哪里，SE里有1的地方就是要平移的方向。<br>第二种，核心：<em>盖章</em><br>SE在原图上平移，只有能够完全包住SE的位置的点置1，其他置0.<br>==腐蚀能够让抹去图片上的小亮点，打断小连接，总之会让图片中亮处整体缩小。==  </p><p><strong>膨胀（Dilation）：</strong><br>公式：$D(F,k)=F\bigoplus k=\bigcup ({ a-b|a\in F})$<br>同样的两种看法，平移的时候是取并集，盖章的时候是只要SE有于原图区域中重合的地方，中心点就置1。<br>==膨胀能够让图片亮处整体扩大。==  </p><p><strong>开（Open）：</strong><br>先腐蚀后膨胀。<br>==可以抹去图片中size小于SE的点和连接，而不会对其他的部分造成大的破坏。==  </p><p><strong>闭（Close）：</strong><br>先膨胀再腐蚀。<br>==可以填补小于SE size的空洞，弥合size小于SE的裂缝，而不会对其他的部分造成大的破坏。==  </p><hr><h2 id="组合算法"><a href="#组合算法" class="headerlink" title="组合算法"></a>组合算法</h2><h3 id="Distance-Transform-距离变换"><a href="#Distance-Transform-距离变换" class="headerlink" title="Distance Transform(距离变换)"></a>Distance Transform(距离变换)</h3><p>这种操作就是用一个flat的SE，给原图作连续的腐蚀，原图上每个点的值替换为n(最后拉伸到0-255)，这个点在第n次腐蚀时消失。<br>直观感觉就是将图片中间的点变亮，周围的点变暗，此时二值图变为灰度图。  </p><h3 id="Skeleton-骨架提取"><a href="#Skeleton-骨架提取" class="headerlink" title="Skeleton(骨架提取)"></a>Skeleton(骨架提取)</h3><p>这种操作直观上是提取出原图形状的中心线，即骨架。<br>是有公式的：<br>$Result = \bigcup S_i(F)$<br>$S_i(F) = F \bigodot r_ik - {(F \bigodot r_ik)\circ r_ik}$</p><h3 id="Edge-形态学边缘"><a href="#Edge-形态学边缘" class="headerlink" title="Edge(形态学边缘)"></a>Edge(形态学边缘)</h3><p>用原图减去腐蚀后的图，或者用膨胀图减去原图，或者用膨胀图减去腐蚀图。<br>都可以得到原图物体的边缘。  </p><h3 id="Conditional-Dilation-条件膨胀"><a href="#Conditional-Dilation-条件膨胀" class="headerlink" title="Conditional Dilation(条件膨胀)"></a>Conditional Dilation(条件膨胀)</h3><p>这是一个很有意思，也很有用的算法。<br>有什么用呢？–==可以通过这个算法去分离原图中两个不相连的part。==<br>条件是只要知道一个物体的一个点在哪里。<br>然后就对这个点作连续膨胀，每次膨胀都和原图作逻辑操作中的“与“操作。<br>这样就可以保证膨胀出的内容不会超过原图的内容。<br>而当每次”与“之后稳定了，就分出了想要的part。  </p><hr><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>这里的算法都可以在我的GitHub里的<a href="https://github.com/Easonyesheng/DIP_GUI">项目</a>里找到<br>该项目是一个包括阈值分割、卷积滤波、形态学和灰度形态学的数字图像处理算法集合<br>用法见readme文件。<br>且带有GUI，有很好的演示效果<br>觉得可以别忘了star哦  </p>]]></content>
    
    
    <summary type="html">二值形态学。</summary>
    
    
    
    
    <category term="数字图像处理" scheme="http://yoursite.com/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>数字图像处理总结2</title>
    <link href="http://yoursite.com/2020/08/13/DIP2/"/>
    <id>http://yoursite.com/2020/08/13/DIP2/</id>
    <published>2020-08-13T06:41:07.000Z</published>
    <updated>2020-08-13T06:44:33.598Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数字图像处理总结2"><a href="#数字图像处理总结2" class="headerlink" title="数字图像处理总结2"></a>数字图像处理总结2</h1><p>卷积运算和图像滤波</p><hr><h2 id="卷积运算"><a href="#卷积运算" class="headerlink" title="卷积运算"></a>卷积运算</h2><p>对图像的操纵分为点操作，代数操作，几何操作和领域操作。<br>卷积运算就是领域操作中的一个，而提到卷积，就不得不说他的姊妹correlation。<br>话不多说，先看公式：<br>convolution : $f*w=\sum_{(a,b)\in w}f(x-a,y-b)w(a,b)$<br>correlation : $f \bigotimes w=\sum _{(a,b) \in w}f(x+a,y+b)w(a,b) $<br>f是原图，k是kernel。a,b是kernel中的点坐标，默认kernel的中心坐标为（0，0）。<br>可以看出两者的区别主要是原图的坐标变换是+ or -<br>而且因为convolution是 - ，在代码中具体运算时，需要将kernel旋转$180^\circ$。<br>一句话描述卷积的过程：对一个以某点为中心，kernel大小的原图区域，对应乘上旋转过的kernel的元素并求和，结果来作为kernel中心那个像素的新的灰度值，对图中所有点作该操作，就是一个卷积。  </p><hr><h2 id="图像滤波"><a href="#图像滤波" class="headerlink" title="图像滤波"></a>图像滤波</h2><p>图像滤波就是用不同的kernel进行卷积操作。<br>根据kernel的不同，又分为很多目的不同的操作，如边缘检测、图像平滑等。<br>下面就举几个常见的例子：  </p><hr><h3 id="Edge-Detection"><a href="#Edge-Detection" class="headerlink" title="Edge Detection"></a>Edge Detection</h3><p><strong>典型算子：</strong><br>Roberts：<br>$$<br>\left |<br> \begin{matrix}<br>  -1 &amp; 0 \<br>  0 &amp; 1 \<br> \end{matrix}<br>\right |<br>$$<br>$$<br>\left |<br> \begin{matrix}<br>  0 &amp; -1 \<br>  1 &amp; 0 \<br> \end{matrix}<br>\right |<br>$$</p><p>Prewitt:<br>$$<br>\left |<br> \begin{matrix}<br>  -1 &amp; -1 &amp; -1 \<br>  0 &amp; 0 &amp; 0 \<br>  1 &amp; 1 &amp; 1 \<br> \end{matrix}<br>\right |<br>$$<br>$$<br>\left |<br> \begin{matrix}<br>  -1 &amp; 0 &amp; 1 \<br>  -1 &amp; 0 &amp; 1 \<br>  -1 &amp; 0 &amp; 1 \<br> \end{matrix}<br>\right |<br>$$<br>Sobel:<br>$$<br>\left |<br> \begin{matrix}<br>  -1 &amp; -2 &amp; -1 \<br>  0 &amp; 0 &amp; 0 \<br>  1 &amp; 2 &amp; 1 \<br> \end{matrix}<br>\right |<br>$$<br>$$<br>\left |<br> \begin{matrix}<br>  -1 &amp; 0 &amp; 1 \<br>  -2 &amp; 0 &amp; 2 \<br>  -1 &amp; 0 &amp; 1 \<br> \end{matrix}<br>\right |<br>$$<br>通过观察可以看出，这三个算子都强调不同像素间的差，其实就是离散形式的导数，所以这三个算子都是在求图片的梯度。<br>而求梯度，就是突出变化，也就是能够得到图片的中像素值变化剧烈的地方，也就是边缘。  </p><hr><h3 id="图像平滑"><a href="#图像平滑" class="headerlink" title="图像平滑"></a>图像平滑</h3><p><strong>典型算子：</strong><br>平均滤波：<br>$$<br>\left [<br> \begin{matrix}<br>  1/9 &amp; 1/9 &amp; 1/9 \<br>  1/9 &amp; 1/9 &amp; 1/9 \<br>  1/9 &amp; 1/9 &amp; 1/9 \<br> \end{matrix}<br>\right ]<br>$$<br>中值滤波：<br>这个算子不是寻常的计算算子，而是将3x3范围内的中值作为中心的灰度值。<br>是一种统计学算子。<br>Gaussian:<br>$G(x,y)={1/{2\pi \sigma^2}} \times e^{-{x^2+y^2}/{2\sigma^2}}$<br>这个式子指的是高斯滤波器对应位置的值，其中一个关键元素是$\sigma$，是方差，在滤波时一般自己选定，他决定了高斯分布的峰高和宽（越大越矮、宽）  </p><hr><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>实现时主要是依赖于opencv的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv2.filter2D(img,<span class="number">-1</span>,filter)</span><br></pre></td></tr></table></figure><p>这里的算法都可以在我的GitHub里的<a href="https://github.com/Easonyesheng/DIP_GUI">项目</a>里找到<br>该项目是一个包括阈值分割、卷积滤波、形态学和灰度形态学的数字图像处理算法集合<br>且带有GUI，有很好的演示效果<br>觉得可以别忘了star哦  </p>]]></content>
    
    
    <summary type="html">卷积运算和图像滤波。</summary>
    
    
    
    
    <category term="数字图像处理" scheme="http://yoursite.com/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>数字图像处理总结1</title>
    <link href="http://yoursite.com/2020/08/11/DIP-1/"/>
    <id>http://yoursite.com/2020/08/11/DIP-1/</id>
    <published>2020-08-11T06:01:12.000Z</published>
    <updated>2020-08-13T06:43:26.202Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数字图像处理总结一"><a href="#数字图像处理总结一" class="headerlink" title="数字图像处理总结一"></a>数字图像处理总结一</h1><p>图像概念 &amp; 阈值分割  </p><h2 id="图像"><a href="#图像" class="headerlink" title="图像"></a>图像</h2><p>数字图像描述的是一个二元函数f(x,y)，将图像的坐标和灰度值联系起来。<br>有三种图片，但本质都是灰度图像，像素值也称为灰度值。<br>图像种类分为：<br>    二值图像 – gray level = 0 or 255/1<br>    灰度图像 – gray level in [0,255]<br>    彩色图像 – 三个通道的灰度图片<br>    伪彩图像、高维图片 – 不作详细介绍  </p><h2 id="阈值分割算法"><a href="#阈值分割算法" class="headerlink" title="阈值分割算法"></a>阈值分割算法</h2><p>阈值分割就是利用图片灰度的分布规律，来分割出图片中不同的物体。<br>而每个物体在图片中的都是一个个的正态分布<br>所以阈值分割就需要找到一个阈值来分出几个正态分布<br>而要找到那个阈值，就需要引入一个概念 – 灰度直方图  </p><h3 id="灰度直方图"><a href="#灰度直方图" class="headerlink" title="灰度直方图"></a>灰度直方图</h3><p>就是统计图片中的灰度分布。<br>横坐标是0～255的灰度值，纵坐标是每个灰度值在图片中的出现的个数<br>每一个物体都有在一段灰度值中的分布，可以看出图片中物体的分布<br>找到那个阈值之后，是可以将阈值之下的置为0，之上的置为最高值。<br>但每张图都有不同的阈值，所以需要一个算法，可以针对不同的图，自动找到那个可以分割出的阈值<br>即算法的普适性  </p><h3 id="OTSU"><a href="#OTSU" class="headerlink" title="OTSU"></a>OTSU</h3><p>OTSU是一个可以自动找到分割阈值的算法<br>其核心思想是：<br><strong>将所有像素通过一个阈值分为前景和背景，然后用一个方差来描述两个类距离图像中心的距离的加和，这个方差最大时，两个类分得最开，对应用的阈值最优</strong><br>算法描述：<br>先得到灰度直方图<br>对0-255的每个灰度值，来计算方差<br>方差公式：<br>$$<br>\sigma^2=\omega_0 \omega_1(\mu_1-\mu_0)^2<br>$$<br>得到最大方差对应的阈值作为分割阈值  </p><h3 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h3><p>熵分割也是一种可以自己找到分割需要的阈值的算法<br>熵描述的是信息量<br>而阈值分割问题，其实就是将图片分为前景和背景<br>如果前景信息量大的同时，背景的信息量也很大，那么就说明分割的比较好<br>所以核心思想就是：<br>$$<br>Maximum(H=H_W+H_B)<br>$$  </p><p>算法描述：<br>求出灰度直方图<br>对每个像素值，计算前景背景熵之和<br>得到熵最大的那个阈值作为最终的阈值  </p><p>熵:<br>$$<br>H_b=-\sum^{0 \to t}{p_i log(p_i)}<br>$$  </p><p>$$<br>H_W=-\sum^{t+1 \to 255}{p_ilog(p_i)}<br>$$  </p><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>这里的两种阈值算法都可以在我的GitHub提交的<a href="https://github.com/Easonyesheng/DIP_GUI">项目</a>里找到<br>该项目是一个包括阈值分割、卷积滤波、形态学和灰度形态学的数字图像处理算法集合<br>且带有GUI，有很好的演示效果<br>觉得可以别忘了star哦  </p>]]></content>
    
    
    <summary type="html">图像概念与阈值分割算法。</summary>
    
    
    
    
    <category term="数字图像处理" scheme="http://yoursite.com/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
</feed>
